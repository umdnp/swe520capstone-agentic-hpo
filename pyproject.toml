[project]
name = "agentic-hpo-fl"
description = "SWE 520 Capstone - Agent-based HPO for Federated Learning"
version = "0.1.0"
requires-python = ">=3.12,<4.0"
authors = [{ name = "Jim Prantzalos" }]
license = { file = "LICENSE" }
readme = "README.md"

[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
where = ["src"]
include = ["fedlearn"]

[tool.flwr.app]
publisher = "umich"
name = "swe520capstone-agentic-hpo"

[tool.flwr.app.components]
clientapp = "fedlearn.hpo.client_app:app"
serverapp = "fedlearn.hpo.server_app:app"

[tool.flwr.app.config]
# baseline | static_hpo | agentic_hpo
experiment = "baseline"

# shared settings
num-server-rounds = 20
local-epochs = 3
penalty = "l2"
class-weight = "none"
sgd-learning-rate = "optimal"
#sgd-eta0 = 0.001  # only useful when learning-rate=constant|adaptive

# server_app settings
fraction-train = 1.0
fraction-evaluate = 1.0

# hpo controls
hpo-n-trials = 15
hpo-num-rounds = 2
hpo-metric = "roc_auc"  # or "loss"
hpo-direction = "maximize"  # "maximize" for roc_auc, "minimize" for loss

# agent controls
agent-model = "gpt-5.2"
agent-temperature = 0.2

# convergence controls
detect-convergence = true
terminate-on-convergence = true
convergence-metric = "roc_auc"
convergence-direction = "max"
convergence-min-delta = 0.001
convergence-patience = 3
convergence-warmup-rounds = 3
